{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "re2T2qjbVBqP"
      },
      "outputs": [],
      "source": [
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
            "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
            "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
            "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
            "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
            "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
            "\n",
            "              class  \n",
            "0          dog_bark  \n",
            "1  children_playing  \n",
            "2  children_playing  \n",
            "3  children_playing  \n",
            "4  children_playing  \n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"UrbanSound8K\"\n",
        "\n",
        "metadata_path = os.path.join(DATASET_PATH, \"metadata\", \"UrbanSound8K.csv\")\n",
        "metadata = pd.read_csv(metadata_path)\n",
        "\n",
        "print(metadata.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class Clip:\n",
        "    \"\"\"\n",
        "    Objeto que representa un clip individual del UrbanSound8K.\n",
        "    Emula el estilo de soundata:\n",
        "\n",
        "    - clip.audio -> (y, sr)\n",
        "    - clip.class_label\n",
        "    - clip.class_id\n",
        "    - clip.fold\n",
        "    - clip.file_path\n",
        "    \"\"\"\n",
        "    def __init__(self, clip_id, audio, sr, class_label, class_id, fold, file_path):\n",
        "        self.clip_id = clip_id\n",
        "        self.audio = (audio, sr)\n",
        "        self.class_label = class_label\n",
        "        self.class_id = class_id\n",
        "        self.fold = int(fold)\n",
        "        self.file_path = file_path\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (\n",
        "            f\"Clip(id={self.clip_id}, class='{self.class_label}', \"\n",
        "            f\"class_id={self.class_id}, fold={self.fold})\"\n",
        "        )\n",
        "\n",
        "\n",
        "class UrbanSound8KDataset:\n",
        "    \"\"\"\n",
        "    Dataset wrapper para UrbanSound8K que imita el comportamiento de soundata.\n",
        "\n",
        "    Atributos principales:\n",
        "    - metadata: DataFrame con todo el CSV\n",
        "    - clip_ids: lista de IDs de clip (√≠ndices del DataFrame)\n",
        "    - folds: dict {fold: DataFrame filtrada}\n",
        "\n",
        "    M√©todos principales:\n",
        "    - get_clip(clip_id) -> Clip\n",
        "    - choice_clip() -> Clip aleatorio\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_path=\"UrbanSound8K\", sr=22050):\n",
        "        self.base_path = base_path\n",
        "        self.sr = sr\n",
        "\n",
        "        # Cargar metadata\n",
        "        metadata_path = os.path.join(base_path, \"metadata\", \"UrbanSound8K.csv\")\n",
        "        if not os.path.exists(metadata_path):\n",
        "            raise FileNotFoundError(\n",
        "                f\"No se encontr√≥ el archivo de metadata en: {metadata_path}\"\n",
        "            )\n",
        "\n",
        "        self.metadata = pd.read_csv(metadata_path)\n",
        "\n",
        "        # Limpiar posibles espacios en nombres de columnas\n",
        "        self.metadata.columns = self.metadata.columns.str.strip()\n",
        "\n",
        "        # IDs de clips (usamos el √≠ndice del DataFrame como ID)\n",
        "        self.clip_ids = list(self.metadata.index)\n",
        "\n",
        "        # Precomputar folds 1..10\n",
        "        self.folds = {\n",
        "            fold: self.metadata[self.metadata[\"fold\"] == fold]\n",
        "            for fold in range(1, 11)\n",
        "        }\n",
        "\n",
        "    def get_clip(self, clip_id):\n",
        "        \"\"\"\n",
        "        Devuelve un objeto Clip, cargando el audio desde disco.\n",
        "\n",
        "        clip_id debe ser un √≠ndice v√°lido de self.metadata (0..len-1).\n",
        "        \"\"\"\n",
        "        if clip_id not in self.clip_ids:\n",
        "            raise ValueError(f\"clip_id {clip_id} no es v√°lido.\")\n",
        "\n",
        "        row = self.metadata.loc[clip_id]\n",
        "\n",
        "        fold = int(row[\"fold\"])\n",
        "        filename = row[\"slice_file_name\"]\n",
        "        class_label = row[\"class\"]\n",
        "        class_id = int(row[\"classID\"])\n",
        "\n",
        "        audio_path = os.path.join(self.base_path, \"audio\", f\"fold{fold}\", filename)\n",
        "\n",
        "        if not os.path.exists(audio_path):\n",
        "            raise FileNotFoundError(\n",
        "                f\"No se encontr√≥ el archivo de audio en: {audio_path}\"\n",
        "            )\n",
        "\n",
        "        # Cargar audio como mono, remuestreado a self.sr\n",
        "        audio, sr = librosa.load(audio_path, sr=self.sr, mono=True)\n",
        "\n",
        "        return Clip(\n",
        "            clip_id=clip_id,\n",
        "            audio=audio,\n",
        "            sr=sr,\n",
        "            class_label=class_label,\n",
        "            class_id=class_id,\n",
        "            fold=fold,\n",
        "            file_path=audio_path,\n",
        "        )\n",
        "\n",
        "    def choice_clip(self):\n",
        "        \"\"\"Devuelve un Clip aleatorio del dataset.\"\"\"\n",
        "        cid = random.choice(self.clip_ids)\n",
        "        return self.get_clip(cid)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.clip_ids)\n",
        "\n",
        "    @property\n",
        "    def num_clips(self):\n",
        "        return len(self.clip_ids)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"UrbanSound8KDataset(num_clips={len(self)}, folds=10)\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3LE7Esupfqn"
      },
      "outputs": [],
      "source": [
        "SR = 22050\n",
        "DURATION = 4.0\n",
        "N_MFCC = 40\n",
        "\n",
        "\n",
        "dataset = UrbanSound8KDataset(\"UrbanSound8K\", sr=SR)\n",
        "example_clip = dataset.choice_clip()\n",
        "\n",
        "def load_clip_mfcc(clip):\n",
        "    y, sr = clip.audio\n",
        "\n",
        "    # Resample\n",
        "    if sr != SR:\n",
        "        y = librosa.resample(y, orig_sr=sr, target_sr=SR)\n",
        "\n",
        "    # Asegurar duraci√≥n fija\n",
        "    max_len = int(SR * DURATION)\n",
        "    if len(y) < max_len:\n",
        "        y = np.pad(y, (0, max_len - len(y)))\n",
        "    else:\n",
        "        y = y[:max_len]\n",
        "\n",
        "    # Calcular MFCC\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=SR, n_mfcc=N_MFCC)\n",
        "    return mfcc  # shape: (40, T)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "OQ-32Gblprnb"
      },
      "outputs": [],
      "source": [
        "def load_data_for_fold(dataset, test_fold):\n",
        "    X_train, y_train = [], []\n",
        "    X_test, y_test = [], []\n",
        "\n",
        "    for cid in dataset.clip_ids:\n",
        "        clip = dataset.get_clip(cid)\n",
        "        mfcc = load_clip_mfcc(clip)\n",
        "        label = clip.class_id\n",
        "        fold = clip.fold\n",
        "\n",
        "        if fold == test_fold:\n",
        "            X_test.append(mfcc)\n",
        "            y_test.append(label)\n",
        "        else:\n",
        "            X_train.append(mfcc)\n",
        "            y_train.append(label)\n",
        "\n",
        "    return np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "yfYyaf_hps9w"
      },
      "outputs": [],
      "source": [
        "def prepare_lstm_features(X):\n",
        "    X_out = []\n",
        "    for mfcc in X:\n",
        "        X_out.append(mfcc.T)  # (40, T) ‚Üí (T, 40)\n",
        "    return np.array(X_out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_Pex-ihGpuf3"
      },
      "outputs": [],
      "source": [
        "def build_lstm_model(n_timesteps, n_features):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(n_timesteps, n_features)),\n",
        "        layers.LSTM(64, return_sequences=True),\n",
        "        layers.LSTM(32),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "nFubTsFGqLgJ",
        "outputId": "1c561ecd-360a-43f5-d323-f53210e50065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===================================================\n",
            "üîµ INICIANDO 10-FOLD CROSS VALIDATION (LSTM)\n",
            "===================================================\n",
            "\n",
            "\n",
            "===================================================\n",
            "üöÄ Ejecutando Fold 1 ...\n",
            "===================================================\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1: Train=7859, Test=873\n",
            "Shapes MFCC: train=(7859, 40, 173), test=(873, 40, 173)\n",
            "Shapes LSTM: train=(7859, 173, 40), test=(873, 173, 40)\n",
            "Epoch 1/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 83ms/step - accuracy: 0.4190 - loss: 1.7328 - val_accuracy: 0.3562 - val_loss: 1.8499\n",
            "Epoch 2/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 103ms/step - accuracy: 0.5844 - loss: 1.2619 - val_accuracy: 0.4536 - val_loss: 1.8154\n",
            "Epoch 3/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 95ms/step - accuracy: 0.6380 - loss: 1.1101 - val_accuracy: 0.4777 - val_loss: 1.6882\n",
            "Epoch 4/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 108ms/step - accuracy: 0.6913 - loss: 0.9550 - val_accuracy: 0.4662 - val_loss: 1.8319\n",
            "Epoch 5/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 80ms/step - accuracy: 0.7189 - loss: 0.8749 - val_accuracy: 0.4731 - val_loss: 1.9096\n",
            "Epoch 6/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 75ms/step - accuracy: 0.7554 - loss: 0.7563 - val_accuracy: 0.4685 - val_loss: 1.9653\n",
            "Epoch 7/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 74ms/step - accuracy: 0.7758 - loss: 0.6888 - val_accuracy: 0.4536 - val_loss: 2.0785\n",
            "Epoch 8/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 79ms/step - accuracy: 0.7787 - loss: 0.6731 - val_accuracy: 0.4651 - val_loss: 2.0088\n",
            "Epoch 9/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 147ms/step - accuracy: 0.7867 - loss: 0.6277 - val_accuracy: 0.4880 - val_loss: 1.9401\n",
            "Epoch 10/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 80ms/step - accuracy: 0.8244 - loss: 0.5377 - val_accuracy: 0.4868 - val_loss: 1.9775\n",
            "Epoch 11/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 85ms/step - accuracy: 0.8395 - loss: 0.4821 - val_accuracy: 0.4914 - val_loss: 2.0468\n",
            "Epoch 12/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 192ms/step - accuracy: 0.8558 - loss: 0.4327 - val_accuracy: 0.4903 - val_loss: 2.2315\n",
            "Epoch 13/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 183ms/step - accuracy: 0.8665 - loss: 0.4044 - val_accuracy: 0.4994 - val_loss: 2.2007\n",
            "Epoch 14/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 195ms/step - accuracy: 0.8726 - loss: 0.3816 - val_accuracy: 0.4903 - val_loss: 2.3817\n",
            "Epoch 15/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 197ms/step - accuracy: 0.8766 - loss: 0.3710 - val_accuracy: 0.5109 - val_loss: 2.1874\n",
            "Epoch 16/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 150ms/step - accuracy: 0.8902 - loss: 0.3275 - val_accuracy: 0.4834 - val_loss: 2.5869\n",
            "Epoch 17/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 0.8991 - loss: 0.2979 - val_accuracy: 0.5006 - val_loss: 2.4573\n",
            "Epoch 18/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 126ms/step - accuracy: 0.8969 - loss: 0.3047 - val_accuracy: 0.4914 - val_loss: 2.4807\n",
            "Epoch 19/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 124ms/step - accuracy: 0.9072 - loss: 0.2812 - val_accuracy: 0.5269 - val_loss: 2.5051\n",
            "Epoch 20/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 124ms/step - accuracy: 0.9178 - loss: 0.2510 - val_accuracy: 0.5292 - val_loss: 2.6421\n",
            "\n",
            "üéØ Accuracy del Fold 1: 0.5292\n",
            "---------------------------------------------------\n",
            "\n",
            "===================================================\n",
            "üöÄ Ejecutando Fold 2 ...\n",
            "===================================================\n",
            "\n",
            "Fold 2: Train=7844, Test=888\n",
            "Shapes MFCC: train=(7844, 40, 173), test=(888, 40, 173)\n",
            "Shapes LSTM: train=(7844, 173, 40), test=(888, 173, 40)\n",
            "Epoch 1/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 135ms/step - accuracy: 0.3981 - loss: 1.7479 - val_accuracy: 0.4054 - val_loss: 1.6741\n",
            "Epoch 2/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 174ms/step - accuracy: 0.6071 - loss: 1.2048 - val_accuracy: 0.4437 - val_loss: 1.5641\n",
            "Epoch 3/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 136ms/step - accuracy: 0.6770 - loss: 0.9886 - val_accuracy: 0.4887 - val_loss: 1.4158\n",
            "Epoch 4/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 128ms/step - accuracy: 0.7126 - loss: 0.8848 - val_accuracy: 0.4820 - val_loss: 1.5190\n",
            "Epoch 5/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 132ms/step - accuracy: 0.7557 - loss: 0.7523 - val_accuracy: 0.4966 - val_loss: 1.7472\n",
            "Epoch 6/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 127ms/step - accuracy: 0.7931 - loss: 0.6320 - val_accuracy: 0.5079 - val_loss: 1.8827\n",
            "Epoch 7/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 127ms/step - accuracy: 0.8151 - loss: 0.5709 - val_accuracy: 0.4673 - val_loss: 2.0274\n",
            "Epoch 8/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 126ms/step - accuracy: 0.8296 - loss: 0.5235 - val_accuracy: 0.4561 - val_loss: 2.2301\n",
            "Epoch 9/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 0.8469 - loss: 0.4687 - val_accuracy: 0.4527 - val_loss: 2.2231\n",
            "Epoch 10/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 127ms/step - accuracy: 0.8535 - loss: 0.4501 - val_accuracy: 0.4606 - val_loss: 2.4203\n",
            "Epoch 11/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 124ms/step - accuracy: 0.8645 - loss: 0.4059 - val_accuracy: 0.4887 - val_loss: 2.0697\n",
            "Epoch 12/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 138ms/step - accuracy: 0.8839 - loss: 0.3541 - val_accuracy: 0.5045 - val_loss: 2.1014\n",
            "Epoch 13/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 141ms/step - accuracy: 0.8958 - loss: 0.3204 - val_accuracy: 0.4820 - val_loss: 2.4584\n",
            "Epoch 14/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 129ms/step - accuracy: 0.8986 - loss: 0.3096 - val_accuracy: 0.5045 - val_loss: 2.1318\n",
            "Epoch 15/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 0.9150 - loss: 0.2693 - val_accuracy: 0.4921 - val_loss: 2.5085\n",
            "Epoch 16/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 115ms/step - accuracy: 0.9124 - loss: 0.2746 - val_accuracy: 0.4876 - val_loss: 2.3400\n",
            "Epoch 17/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 80ms/step - accuracy: 0.9211 - loss: 0.2472 - val_accuracy: 0.4718 - val_loss: 2.5299\n",
            "Epoch 18/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 77ms/step - accuracy: 0.9230 - loss: 0.2350 - val_accuracy: 0.5135 - val_loss: 2.4157\n",
            "Epoch 19/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 75ms/step - accuracy: 0.9305 - loss: 0.2218 - val_accuracy: 0.5214 - val_loss: 2.4874\n",
            "Epoch 20/20\n",
            "\u001b[1m246/246\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 74ms/step - accuracy: 0.9331 - loss: 0.2112 - val_accuracy: 0.4707 - val_loss: 2.7051\n",
            "\n",
            "üéØ Accuracy del Fold 2: 0.4707\n",
            "---------------------------------------------------\n",
            "\n",
            "===================================================\n",
            "üöÄ Ejecutando Fold 3 ...\n",
            "===================================================\n",
            "\n",
            "Fold 3: Train=7807, Test=925\n",
            "Shapes MFCC: train=(7807, 40, 173), test=(925, 40, 173)\n",
            "Shapes LSTM: train=(7807, 173, 40), test=(925, 173, 40)\n",
            "Epoch 1/20\n",
            "\u001b[1m244/244\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - accuracy: 0.4063 - loss: 1.7274 - val_accuracy: 0.4281 - val_loss: 1.7509\n",
            "Epoch 2/20\n",
            "\u001b[1m244/244\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 92ms/step - accuracy: 0.5924 - loss: 1.2308 - val_accuracy: 0.4184 - val_loss: 1.9084\n",
            "Epoch 3/20\n",
            "\u001b[1m244/244\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 90ms/step - accuracy: 0.6670 - loss: 1.0189 - val_accuracy: 0.4346 - val_loss: 1.7618\n",
            "Epoch 4/20\n",
            "\u001b[1m244/244\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 94ms/step - accuracy: 0.7021 - loss: 0.9242 - val_accuracy: 0.4357 - val_loss: 1.9386\n",
            "Epoch 5/20\n",
            "\u001b[1m244/244\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 152ms/step - accuracy: 0.7323 - loss: 0.8111 - val_accuracy: 0.4411 - val_loss: 2.1565\n",
            "Epoch 6/20\n",
            "\u001b[1m244/244\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 144ms/step - accuracy: 0.7689 - loss: 0.7140 - val_accuracy: 0.4551 - val_loss: 2.0943\n",
            "Epoch 7/20\n",
            "\u001b[1m244/244\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 138ms/step - accuracy: 0.7934 - loss: 0.6434 - val_accuracy: 0.4389 - val_loss: 2.3045\n",
            "Epoch 8/20\n",
            "\u001b[1m183/244\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m7s\u001b[0m 130ms/step - accuracy: 0.8082 - loss: 0.5961"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m lstm_model = build_lstm_model(n_timesteps, n_features)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# 4. Entrenar\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m history = \u001b[43mlstm_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train_lstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_lstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     38\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# 5. Evaluar\u001b[39;00m\n\u001b[32m     41\u001b[39m test_loss, test_acc = lstm_model.evaluate(X_test_lstm, y_test, verbose=\u001b[32m0\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Devlepa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Devlepa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:399\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    398\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Devlepa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:241\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    239\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    240\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    243\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Devlepa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Devlepa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Devlepa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Devlepa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Devlepa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Devlepa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Devlepa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Devlepa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Devlepa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "accuracies = []\n",
        "\n",
        "print(\"\\n===================================================\")\n",
        "print(\"üîµ INICIANDO 10-FOLD CROSS VALIDATION (LSTM)\")\n",
        "print(\"===================================================\\n\")\n",
        "\n",
        "for fold in range(1, 11):\n",
        "\n",
        "    print(f\"\\n===================================================\")\n",
        "    print(f\"üöÄ Ejecutando Fold {fold} ...\")\n",
        "    print(\"===================================================\\n\")\n",
        "\n",
        "    # 1. Cargar datos del fold\n",
        "    X_train_raw, y_train, X_test_raw, y_test = load_data_for_fold(dataset, test_fold=fold)\n",
        "\n",
        "    print(f\"Fold {fold}: Train={len(X_train_raw)}, Test={len(X_test_raw)}\")\n",
        "    print(f\"Shapes MFCC: train={X_train_raw.shape}, test={X_test_raw.shape}\")\n",
        "\n",
        "    # 2. Preparar MFCC ‚Üí LSTM (T, 40)\n",
        "    X_train_lstm = prepare_lstm_features(X_train_raw)\n",
        "    X_test_lstm  = prepare_lstm_features(X_test_raw)\n",
        "\n",
        "    n_timesteps = X_train_lstm.shape[1]\n",
        "    n_features  = X_train_lstm.shape[2]\n",
        "\n",
        "    print(f\"Shapes LSTM: train={X_train_lstm.shape}, test={X_test_lstm.shape}\")\n",
        "\n",
        "    # 3. Crear modelo LSTM\n",
        "    lstm_model = build_lstm_model(n_timesteps, n_features)\n",
        "\n",
        "    # 4. Entrenar\n",
        "    history = lstm_model.fit(\n",
        "        X_train_lstm, y_train,\n",
        "        epochs=20,\n",
        "        batch_size=32,\n",
        "        validation_data=(X_test_lstm, y_test),\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # 5. Evaluar\n",
        "    test_loss, test_acc = lstm_model.evaluate(X_test_lstm, y_test, verbose=0)\n",
        "    accuracies.append(test_acc)\n",
        "\n",
        "    print(f\"\\nüéØ Accuracy del Fold {fold}: {test_acc:.4f}\")\n",
        "    print(\"---------------------------------------------------\")\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# RESULTADOS FINALES\n",
        "# ---------------------------------------------------\n",
        "import numpy as np\n",
        "\n",
        "print(\"\\n===================================================\")\n",
        "print(\"üîµ RESULTADOS DEL 10-FOLD CROSS VALIDATION (LSTM)\")\n",
        "print(\"===================================================\\n\")\n",
        "\n",
        "print(\"Accuracies por fold:\", accuracies)\n",
        "\n",
        "mean_acc = np.mean(accuracies)\n",
        "std_acc  = np.std(accuracies)\n",
        "\n",
        "print(f\"\\nüìå Accuracy promedio:      {mean_acc:.4f}\")\n",
        "print(f\"üìå Desviaci√≥n est√°ndar:    {std_acc:.4f}\")\n",
        "\n",
        "print(\"\\n===================================================\")\n",
        "print(\"üèÅ ENTRENAMIENTO COMPLETO\")\n",
        "print(\"===================================================\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
